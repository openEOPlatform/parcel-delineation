{
  "loadcollection1": {
    "process_id": "load_collection",
    "arguments": {
      "bands": [
        "B04",
        "B08",
        "SCL"
      ],
      "id": "TERRASCOPE_S2_TOC_V2",
      "spatial_extent": {
        "west": 5.047760653506095,
        "south": 51.213840995229475,
        "east": 5.06244073203276,
        "north": 51.22255852538937
      },
      "temporal_extent": [
        "2019-01-01",
        "2019-09-30"
      ]
    }
  },
  "maskscldilation1": {
    "process_id": "mask_scl_dilation",
    "arguments": {
      "data": {
        "from_node": "loadcollection1"
      },
      "scl_band_name": "SCL"
    }
  },
  "ndvi1": {
    "process_id": "ndvi",
    "arguments": {
      "data": {
        "from_node": "maskscldilation1"
      },
      "nir": "B08",
      "red": "B04"
    }
  },
  "applydimension1": {
    "process_id": "apply_dimension",
    "arguments": {
      "data": {
        "from_node": "ndvi1"
      },
      "dimension": "t",
      "process": {
        "process_graph": {
          "runudf1": {
            "process_id": "run_udf",
            "arguments": {
              "data": {
                "from_parameter": "data"
              },
              "runtime": "Python",
              "udf": "# -*- coding: utf-8 -*-\n# Uncomment the import only for coding support\nfrom openeo.udf import XarrayDataCube\nfrom typing import Dict\n\n\ndef apply_datacube(cube: XarrayDataCube, context: Dict) -> XarrayDataCube:\n\n    import numpy\n\n    # set how much images to select in the order of highest number of clear pixels\n    maxlayers=12\n    if context is not None:\n        maxlayers=context.get('maxlayers',maxlayers)\n\n    # get the underlying xarray\n    inputarray=cube.get_array()\n    \n    # prepare uniform coordinates\n    trange=numpy.arange(numpy.datetime64(str(inputarray.t.dt.year.values[0])+'-01-01'),numpy.datetime64(str(inputarray.t.dt.year.values[0])+'-01-31'))\n    \n    # order the layers by decreasing number of clear pixels\n    counts=list(sorted(zip(\n        [i for i in range(inputarray.shape[0])],\n        inputarray.count(dim=['x','y']).values[:,0]\n    ), key=lambda i: i[1], reverse=True))\n    \n    # return the selected ones \n    resultarray=inputarray[ [i[0] for i in counts[:maxlayers]] ]\n    resultarray=resultarray.sortby(resultarray.t,ascending=True)\n    resultarray=resultarray.assign_coords(t=trange[:maxlayers])   \n    return XarrayDataCube(resultarray)\n\n",
              "version": "latest"
            },
            "result": true
          }
        }
      }
    }
  },
  "applydimension2": {
    "process_id": "apply_dimension",
    "arguments": {
      "data": {
        "from_node": "applydimension1"
      },
      "dimension": "t",
      "process": {
        "process_graph": {
          "runudf2": {
            "process_id": "run_udf",
            "arguments": {
              "data": {
                "from_parameter": "data"
              },
              "runtime": "Python",
              "udf": "'''\nCreated on Jun 9, 2020\n\n@author: banyait\n'''\n\nimport os\nfrom tensorflow.keras.models import load_model\nimport numpy as np\nimport gc\nimport logging\nimport itertools\nfrom tensorflow.keras.backend import clear_session\nfrom xarray.core.common import zeros_like, ones_like\nfrom xarray.ufuncs import isnan as ufuncs_isnan\nimport xarray\nfrom openeo.udf import XarrayDataCube\nfrom typing import Dict\n\n# needed because joblib hijacks root logger\nlogging.basicConfig(level=logging.INFO)\n\nclass Segmentation():\n\n    def __init__(self, logger=None):\n        if logger is None:\n            self.log = logging.getLogger(__name__)\n        else: self.log=logger\n        self.models=None\n        #set_visible_devices([], 'GPU')\n    \n    ################ FUNCTIONS ############################\n    def load_models(self,modeldir):\n        # Load the models and make the prediction functions\n        if self.models is None: \n            self.log.info('Loading convolutional neural networks ...')\n            weightsmodel1 = os.path.join(modeldir, 'BelgiumCropMap_unet_3BandsGenerator_Network1.h5')\n            weightsmodel2 = os.path.join(modeldir, 'BelgiumCropMap_unet_3BandsGenerator_Network2.h5')\n            weightsmodel3 = os.path.join(modeldir, 'BelgiumCropMap_unet_3BandsGenerator_Network3.h5')\n            self.models = [\n                load_model(weightsmodel1),\n                load_model(weightsmodel2),\n                load_model(weightsmodel3)\n            ]\n        else: self.log.info('Reusing convolutional neural networks ...')\n        return self.models\n    \n    #TODO move masking out\n    def processWindow(self, models, window, data):\n    \n        model1 = models[0]\n        model2 = models[1]\n        model3 = models[2]\n        \n        # Read the data\n        ndvi_stack = data['s2_ndvi'].values.copy()\n        mask_stack = data['s2_mask'].values.copy()\n    \n        # Mask the ndvi data\n        ndvi_stack[mask_stack == 1] = 255\n        ndvi_stack[ndvi_stack > 250] = 255\n    \n        # Count the amount of invalid data per acquisition and sort accordingly\n        sum_invalid = np.sum(ndvi_stack == 255, axis=(0, 1))\n    \n        # if we have enough clear images, we're good to go.\n        if len(np.where(sum_invalid == 0)[0]) > 3:\n            allgood = 1\n            self.log.debug((f'Found {len(np.where(sum_invalid == 0)[0])} clear acquisitions -> good to go'))\n            ndvi_stack = ndvi_stack[:, :, np.where(sum_invalid == 0)[0]]\n    \n        # else we need to add some bad images\n        else:\n            self.log.debug((f'Found {len(np.where(sum_invalid == 0)[0])} clear acquisitions -> appending some bad images as well!'))\n            allgood = 0\n            idxsorted = np.argsort(sum_invalid)\n            ndvi_stack = ndvi_stack[:, :, idxsorted[0:4]]\n    \n        # Fill the NaN values\n        ndvi_stack[ndvi_stack == 255] = 0\n    \n        # To fractional number\n        ndvi_stack = ndvi_stack / 250.\n    \n        # Now make sure we can run this window\n        nrValidBands = ndvi_stack.shape[2]\n    \n        # If the stack hasn't at least 3 bands, we cannot process this window\n        if nrValidBands < 3:\n            self.log.warning('Not enough input data for window {} -> skipping!'.format(str(window)))\n            clear_session()\n            #del model1, model2, model3 # TODO only when spark\n            gc.collect()\n            return None\n        else:\n            # We'll do 12 predictions: use 3 networks, and for each randomly take 3 NDVI bands and repeat 4 times\n            prediction = np.zeros((128, 128, 12))\n            for i in range(4):\n                prediction[:, :, i] = np.squeeze(\n                    model1.predict(ndvi_stack[:, :, np.random.choice(np.arange(nrValidBands), size=3, replace=False)]\n                                   .reshape(1, 128 * 128, 3)).reshape((128, 128)))\n            for i in range(4):\n                prediction[:, :, i + 4] = np.squeeze(\n                    model2.predict(ndvi_stack[:, :, np.random.choice(np.arange(nrValidBands), size=3, replace=False)]\n                                   .reshape(1, 128 * 128, 3)).reshape((128, 128)))\n            for i in range(4):\n                prediction[:, :, i + 8] = np.squeeze(\n                    model3.predict(ndvi_stack[:, :, np.random.choice(np.arange(nrValidBands), size=3, replace=False)]\n                                   .reshape(1, 128 * 128, 3)).reshape((128, 128)))\n    \n    \n            # Final prediction is the median of all predictions per pixel\n            clear_session() # IMPORTANT TO AVOID MEMORY LEAK ON THE EXECUTORS!!!\n            # del model1, model2, model3 # TODO only when spark\n            gc.collect()\n            return window, (np.median(prediction, axis=2), allgood)\n    \n    \n        \n    def processWindowList(self,windowlist,modeldir,inputdata,stride):\n        bbox=(\n            (min([i[0][0] for i in windowlist]), max([i[0][1] for i in windowlist])),\n            (min([i[1][0] for i in windowlist]), max([i[1][1] for i in windowlist]))\n        )\n        #retvals=[]\n        result=zeros_like(inputdata['s2_ndvi'][:,:,0]).astype(np.ubyte)\n        models=self.load_models(modeldir)\n        for window in windowlist:\n            inputdatawindow={}\n            for (k,v) in inputdata.items(): inputdatawindow[k]=v[\n                window[0][0]-bbox[0][0]:window[0][1]-bbox[0][0],\n                window[1][0]-bbox[1][0]:window[1][1]-bbox[1][0]\n            ]\n            window, (winresult, allgood) = self.processWindow(models, window, inputdatawindow)\n            if winresult is not None:\n                # Scale to byte\n                data = winresult # winresult[stride:-stride, stride:-stride]\n                data = data * 250\n                data = data.astype(np.ubyte) # TODO move this out to file-based\n                # when a window is on the side of the list, then including it\n                #  - center 64x64 windows always come from the 128x128 centers \n                #  - bbox border is filled randomly as the windows were processed\n                sxmin= stride if window[0][0]!=bbox[0][0] else 0\n                sxmax=-stride if window[0][1]!=bbox[0][1] else 0\n                symin= stride if window[1][0]!=bbox[1][0] else 0\n                symax=-stride if window[1][1]!=bbox[1][1] else 0\n                # write window to destination\n                subWindow = (\n                    (window[0][0]+sxmin, window[0][1]+sxmax),\n                    (window[1][0]+symin, window[1][1]+symax)\n                )\n                # We had to pull in some bad images as well, need to log this!\n                if allgood == 0: self.log.debug(\"Window {} successfully processed, but some bad images were included!\".format(window))\n                else: self.log.debug(\"Window {} successfully processed!\".format(window))\n                result[\n                    subWindow[0][0]-bbox[0][0]:subWindow[0][1]-bbox[0][0],\n                    subWindow[1][0]-bbox[1][0]:subWindow[1][1]-bbox[1][0]\n                ]=data[\n                    0+sxmin:data.shape[0]+sxmax,\n                    0+symin:data.shape[1]+symax\n                ]\n            else:\n                self.log.error('Window {} returned an invalid result -> should investigate!'.format(window))\n    \n        #return retvals\n        adjusted_bbox=((bbox[0][0]+stride,bbox[0][1]-stride),(bbox[1][0]+stride,bbox[1][1]-stride))\n        return (adjusted_bbox,result)\n    \n    \n    def computeWindowLists(self, bboxWindow, imageSize, windowsize, stride):\n        '''\n        bboxWindow: ((xmin,xmax),(ymin,ymax)) or None to use full image\n        imageSize: (width,height)\n        windowSize: size of blocks to split bboxWindow\n        stride: overlaps width neighbours\n        \n        returns: 2d list of windows, where each window element is in the format ((xmin,xmax),(ymin,ymax))\n        '''\n        if bboxWindow is None:  bbox=[0,0,imageSize[0],imageSize[1]]\n        else: bbox=[bboxWindow[0][0],bboxWindow[1][0],bboxWindow[0][1],bboxWindow[1][1]]\n        \n        # because sride amount of frame is not filled in the wind with windowsize -> bbox has to be enlarged\n        bbox[0]= bbox[0]-stride if bbox[0]-stride>=0 else 0 \n        bbox[1]= bbox[1]-stride if bbox[1]-stride>=0 else 0\n        bbox[2]= bbox[2]+stride if bbox[2]+stride<=imageSize[0] else imageSize[0]\n        bbox[3]= bbox[3]+stride if bbox[3]+stride<=imageSize[1] else imageSize[1]\n         \n        # We need to check if we're at the end of the master image\n        # We have to make sure we have a full subtile\n        # so we need to expand such tile and the resulting overlap\n        # with previous subtile is not an issue\n        windowlist=[]\n        for xStart in range(bbox[0], bbox[2], windowsize - 2 * stride):\n            \n            windowlist.append([])\n            \n            if xStart + windowsize > bbox[2]:\n                xStart = bbox[2] - windowsize\n                xEnd = bbox[2]\n            else:\n                xEnd = xStart + windowsize\n    \n            for yStart in range(bbox[1], bbox[3], windowsize - 2 * stride):\n                if yStart + windowsize > bbox[3]:\n                    yStart = bbox[3] - windowsize\n                    yEnd = bbox[3]\n                else:\n                    yEnd = yStart + windowsize\n    \n                windowlist[len(windowlist)-1].append(((xStart, xEnd), (yStart, yEnd)))\n        \n                if (yEnd==bbox[3]): break\n            if (xEnd==bbox[2]): break\n    \n        return windowlist\n\ndef apply_datacube(cube: XarrayDataCube, context: Dict) -> XarrayDataCube:\n\n    modeldir='/data/users/Public/driesseb/fielddelineation'\n    if context is not None:\n        modeldir=context.get('modeldir',modeldir)\n    \n    cubearray:xarray.DataArray = ((cube.get_array()+0.08)*250.)[:,0,:,:]\n    inputarray=cubearray.transpose('x','y','t')\n    inputmask=ones_like(inputarray)\n    inputmask=inputmask.where(ufuncs_isnan(inputarray), 0.)\n    inputdata={\n        's2_ndvi': inputarray,\n        's2_mask': inputmask\n    }\n\n    s=Segmentation()\n    windows=s.computeWindowLists(None, inputarray.shape[0:2], windowsize=128, stride=32)\n    windowlist=list(itertools.chain.from_iterable(windows))\n\n    result=s.processWindowList(\n        windowlist, \n        modeldir, \n        inputdata, \n        32\n    )[1]\n    \n    result=result.astype(np.float64)\n    result=result.expand_dims('bands',0).assign_coords(bands=['delineation'])\n    result=result.expand_dims('t',0).assign_coords(t=[np.datetime64(str(cubearray.t.dt.year.values[0])+'-01-01')])\n    return XarrayDataCube(result)\n    \n    \n        \n    \n    \n",
              "version": "latest"
            },
            "result": true
          }
        }
      }
    }
  },
  "applydimension3": {
    "process_id": "apply_dimension",
    "arguments": {
      "data": {
        "from_node": "applydimension2"
      },
      "dimension": "t",
      "process": {
        "process_graph": {
          "runudf3": {
            "process_id": "run_udf",
            "arguments": {
              "data": {
                "from_parameter": "data"
              },
              "runtime": "Python",
              "udf": "# -*- coding: utf-8 -*-\n# Uncomment the import only for coding support\nfrom openeo.udf import XarrayDataCube\nfrom typing import Dict\n\n\ndef apply_datacube(cube: XarrayDataCube, context: Dict) -> XarrayDataCube:\n    import numpy as np\n    from skimage import segmentation\n    from skimage.filters import sobel\n    from skimage.future import graph\n    import xarray\n\n    # get the underlying numpy array\n    inarray=cube.get_array().squeeze('t',drop=True).squeeze('bands',drop=True)\n    inimage=inarray.values#(inarray.values*inarray.values)/255\n    inimage-=np.min(inimage)\n    inimage=inimage*249./np.max(inimage)\n    image=np.clip((inimage-0.3*250)*2,0.,249.)\n\n    # compute edges\n    edges=sobel(image)\n\n    # Perform felzenszwalb segmentation\n    segment = np.array(segmentation.felzenszwalb(image, scale=1, sigma=0., min_size=30, multichannel=False)).astype(np.int32)\n    # Perform the rag boundary analysis and merge the segments\n    bgraph = graph.rag_boundary(segment, edges)\n    # merging segments\n    mergedsegment = graph.cut_threshold(segment, bgraph, 0.15, in_place=False)\n    # segments start from 0, therefore the 0th has to be moved\n    mergedsegment[mergedsegment==0]=np.max(mergedsegment)+1\n    # We currently take 0.3 as the binary threshold to distinguish between segments of fields and other segments.\n    # This could definitely be improved and made more objective.\n    # NOTE: new implementation uses scaled data, so threshold needs to be scaled as well!\n    mergedsegment[image==0] = 0\n    mergedsegment[mergedsegment < 0] = 0\n\n    outarr=xarray.DataArray(mergedsegment.reshape(cube.get_array().shape),dims=cube.get_array().dims,coords=cube.get_array().coords)\n    outarr=outarr.astype(np.float64)\n    outarr=outarr.where(outarr!=0,np.nan)\n\n    return XarrayDataCube(outarr)\n",
              "version": "latest"
            },
            "result": true
          }
        }
      }
    }
  },
  "rastertovector1": {
    "process_id": "raster_to_vector",
    "arguments": {
      "data": {
        "from_node": "applydimension3"
      }
    },
    "result": true
  }
}